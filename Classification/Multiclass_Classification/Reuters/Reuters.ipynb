{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "#set_session(tf.Session(config=config))\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiying newswires: Reuters, a multiclass classification example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 这个例子整理自[《Deep Learning with Python》](https://book.douban.com/subject/27038207/) 3.5节"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.探索数据-Reuters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ [Reuters](http://www.daviddlewis.com/resources/testcollections/reuters21578/)数据集，本数据库包含来自路透社的11,228条新闻，分为了46个主题。与IMDB库一样，每条新闻被编码为一个词下标的序列。\n",
    "+ 我们希望输入新闻的内容，得到该新闻的分类，这是一个多类分类问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import callbacks\n",
    "from keras import regularizers\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:(8982,), training labels shape:(8982,)\n",
      "Test data shape:(2246,), test labels shape:(2246,)\n"
     ]
    }
   ],
   "source": [
    "# 导入数据\n",
    "max_featuers = 10000\n",
    "(x_train, y_train),(x_test, y_test) = reuters.load_data(num_words=max_featuers)\n",
    "print('Training data shape:{}, training labels shape:{}'.format(x_train.shape, y_train.shape))\n",
    "print('Test data shape:{}, test labels shape:{}'.format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.   Length    Content(first 10 words)                                     Targets   \n",
      "0     87        [1, 2, 2, 8, 43, 10, 447, 5, 25, 207]                       3         \n",
      "1     56        [1, 3267, 699, 3434, 2295, 56, 2, 7511, 9, 56]              4         \n",
      "2     139       [1, 53, 12, 284, 15, 14, 272, 26, 53, 959]                  3         \n",
      "3     224       [1, 4, 686, 867, 558, 4, 37, 38, 309, 2276]                 4         \n",
      "4     101       [1, 8295, 111, 8, 25, 166, 40, 638, 10, 436]                4         \n",
      "5     116       [1, 4, 37, 38, 309, 213, 349, 1632, 48, 193]                4         \n",
      "6     100       [1, 56, 5539, 925, 149, 8, 16, 23, 931, 3875]               4         \n",
      "7     100       [1, 53, 648, 26, 14, 749, 26, 39, 6207, 5466]               3         \n",
      "8     82        [1, 178, 53, 321, 26, 14, 948, 26, 178, 39]                 3         \n",
      "9     106       [1, 56, 7224, 81, 40, 1175, 174, 2, 6, 1793]                16        \n",
      "10    31        [1, 245, 273, 207, 156, 53, 74, 160, 26, 14]                3         \n",
      "11    59        [1, 56, 141, 5618, 1607, 149, 8, 16, 33, 223]               3         \n",
      "12    65        [1, 2, 81, 8, 16, 625, 42, 120, 7, 1679]                    4         \n",
      "13    316       [1, 248, 409, 166, 1461, 1284, 3906, 8, 4, 495]             4         \n",
      "14    527       [1, 4, 113, 23, 133, 6, 433, 226, 7, 1182]                  19        \n",
      "15    76        [1, 577, 9, 355, 430, 21, 4, 2222, 5, 4]                    8         \n",
      "16    114       [1, 945, 65, 111, 8, 10, 498, 40, 85, 2120]                 16        \n",
      "17    17        [1, 486, 341, 785, 26, 14, 482, 26, 255, 606]               3         \n",
      "18    91        [1, 53, 19, 296, 15, 14, 258, 26, 53, 959]                  3         \n",
      "19    77        [1, 7567, 851, 260, 542, 159, 13, 52, 29, 23]               21        \n"
     ]
    }
   ],
   "source": [
    "# 显示部分数据\n",
    "#print('No.\\t\\tLength\\t\\tContent(the first 10 words)\\t\\t\\t\\tTarget')\n",
    "print('{:<6}{:<10}{:<60}{:<10}'.format('No.', 'Length', 'Content(first 10 words)', 'Targets'))\n",
    "for i, (x,y) in enumerate(zip(x_train[:20], y_train[:20])):\n",
    "    #target = 'Positive'if y==1 else 'Negative'\n",
    "    print('{:<6}{:<10}{:<60}{:<10}'.format(i, len(x), str(x[:10]), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Class           Training Count        Test Count     \n",
      "         0                  55(0.01)        12(0.01)\n",
      "         1                 432(0.05)       105(0.05)\n",
      "         2                  74(0.01)        20(0.01)\n",
      "         3                3159(0.35)       813(0.36)\n",
      "         4                1949(0.22)       474(0.21)\n",
      "         5                  17(0.00)         5(0.00)\n",
      "         6                  48(0.01)        14(0.01)\n",
      "         7                  16(0.00)         3(0.00)\n",
      "         8                 139(0.02)        38(0.02)\n",
      "         9                 101(0.01)        25(0.01)\n",
      "         10                124(0.01)        30(0.01)\n",
      "         11                390(0.04)        83(0.04)\n",
      "         12                 49(0.01)        13(0.01)\n",
      "         13                172(0.02)        37(0.02)\n",
      "         14                 26(0.00)         2(0.00)\n",
      "         15                 20(0.00)         9(0.00)\n",
      "         16                444(0.05)        99(0.04)\n",
      "         17                 39(0.00)        12(0.01)\n",
      "         18                 66(0.01)        20(0.01)\n",
      "         19                549(0.06)       133(0.06)\n",
      "         20                269(0.03)        70(0.03)\n",
      "         21                100(0.01)        27(0.01)\n",
      "         22                 15(0.00)         7(0.00)\n",
      "         23                 41(0.00)        12(0.01)\n",
      "         24                 62(0.01)        19(0.01)\n",
      "         25                 92(0.01)        31(0.01)\n",
      "         26                 24(0.00)         8(0.00)\n",
      "         27                 15(0.00)         4(0.00)\n",
      "         28                 48(0.01)        10(0.00)\n",
      "         29                 19(0.00)         4(0.00)\n",
      "         30                 45(0.01)        12(0.01)\n",
      "         31                 39(0.00)        13(0.01)\n",
      "         32                 32(0.00)        10(0.00)\n",
      "         33                 11(0.00)         5(0.00)\n",
      "         34                 50(0.01)         7(0.00)\n",
      "         35                 10(0.00)         6(0.00)\n",
      "         36                 49(0.01)        11(0.00)\n",
      "         37                 19(0.00)         2(0.00)\n",
      "         38                 19(0.00)         3(0.00)\n",
      "         39                 24(0.00)         5(0.00)\n",
      "         40                 36(0.00)        10(0.00)\n",
      "         41                 30(0.00)         8(0.00)\n",
      "         42                 13(0.00)         3(0.00)\n",
      "         43                 21(0.00)         6(0.00)\n",
      "         44                 12(0.00)         5(0.00)\n",
      "         45                 18(0.00)         1(0.00)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAFpCAYAAAC24dPRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa850d00eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 对训练标签做统计\n",
    "n_bins = max(y_train) + 1\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.subplot(121)\n",
    "train_num,train_bins, _ = plt.hist(y_train, bins=n_bins, histtype='bar', facecolor='r')\n",
    "train_pdf = train_num / np.sum(train_num)\n",
    "\n",
    "plt.subplot(122)\n",
    "test_num, test_bins, _  = plt.hist(y_test, bins=n_bins, histtype='bar', facecolor='g')\n",
    "test_pdf = test_num / np.sum(test_num)\n",
    "\n",
    "# 输出每种类别所对应的数量\n",
    "print('{:^20}{:^20}{:^20}'.format('Class', 'Training Count', 'Test Count'))\n",
    "for i, train_n, train_p, test_n, test_p in zip(range(n_bins), train_num, train_pdf, test_num, test_pdf):\n",
    "    print('{:^20}{:>10}({:.2f}){:>10}({:.2f})'.format(int(i), int(train_n),train_p, int(test_n), test_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 将数字转换为单词\n",
    "word_index = reuters.get_word_index()\n",
    "num_to_word = { value:key for (key, value) in word_index.items()}\n",
    "def decode_review(num_to_word, review):\n",
    "    # i - 3是因为0, 1, 2代表着'padding','start', 'unknow'， 因此单词的下标真正是从3开始的\n",
    "    decoded = ' '.join( [num_to_word.get(i-3, '?') for i in review])\n",
    "    return decoded\n",
    "decode_review(num_to_word, x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.结论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 这是一个多类分类问题，每种类别的数量分布很不平衡，有的类别有几千个，但是有的类别只有十几个\n",
    "+ 每条数据长度不一致，需要被统一长度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 定位问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 输入数据：$x\\in R^n$, $n$表示长度，$x_i$是一个数字，表示一个单词，不同的$x$，n的值不同\n",
    "+ 输出：$y\\in\\{0, \\dots, 45\\}$, 每个数字表示一种类别\n",
    "+ 问题归类：多类别分类问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  衡量指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 样本类型分布不均匀，是imbalanced data，可能用Precision对数据进行衡量比较OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 验证策略\n",
    "\n",
    "+ hold-out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 准备数据\n",
    "\n",
    "+ 截断太长的数据，填充过短的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Padding\n",
      "Training data shape:(8982, 500), training labels shape:(8982,)\n"
     ]
    }
   ],
   "source": [
    "max_len = 500\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "print('After Padding\\nTraining data shape:{}, test data shape:{}'.format(x_train.shape, x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 基本模型\n",
    "\n",
    "+ 首先确定一个基线，在这个问题中，我们利用随机猜测的力量来估计猜中的概率是多少，以这个概率作为基线。结果显示，基线大概为18%\n",
    "+ 接下来，建立一个模型，能够打败基线即可。这里用上Embedding层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy based on random is :0.18210151380231523\n"
     ]
    }
   ],
   "source": [
    "# 确定基线，即靠猜\n",
    "rand_results = y_test.copy()\n",
    "np.random.shuffle(rand_results)\n",
    "\n",
    "hits_array = rand_results == y_test\n",
    "random_acc = np.sum(hits_array) / len(y_test)\n",
    "print('Accuracy based on random is :{}'.format(random_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_based_model():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Embedding(max_featuers, 32, input_length=max_len))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(46, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7634 samples, validate on 1348 samples\n",
      "Epoch 1/20\n",
      "7634/7634 [==============================] - 10s 1ms/step - loss: 1.8541 - acc: 0.5312 - val_loss: 1.4829 - val_acc: 0.6521\n",
      "Epoch 2/20\n",
      "7634/7634 [==============================] - 3s 414us/step - loss: 0.8690 - acc: 0.7996 - val_loss: 1.2585 - val_acc: 0.7085\n",
      "Epoch 3/20\n",
      "7634/7634 [==============================] - 3s 399us/step - loss: 0.3951 - acc: 0.9230 - val_loss: 1.2860 - val_acc: 0.7122\n",
      "Epoch 4/20\n",
      "7634/7634 [==============================] - 3s 396us/step - loss: 0.2686 - acc: 0.9518 - val_loss: 1.3520 - val_acc: 0.7099\n",
      "Epoch 5/20\n",
      "7634/7634 [==============================] - 6s 784us/step - loss: 0.2179 - acc: 0.9572 - val_loss: 1.4452 - val_acc: 0.7010\n",
      "Epoch 6/20\n",
      "7634/7634 [==============================] - 3s 425us/step - loss: 0.2061 - acc: 0.9583 - val_loss: 1.3599 - val_acc: 0.7092\n",
      "Epoch 7/20\n",
      "7634/7634 [==============================] - 3s 406us/step - loss: 0.1906 - acc: 0.9580 - val_loss: 1.4439 - val_acc: 0.7062\n",
      "Epoch 8/20\n",
      "7634/7634 [==============================] - 3s 395us/step - loss: 0.1834 - acc: 0.9590 - val_loss: 1.3952 - val_acc: 0.7136\n",
      "Epoch 9/20\n",
      "7634/7634 [==============================] - 3s 398us/step - loss: 0.1844 - acc: 0.9589 - val_loss: 1.4438 - val_acc: 0.7070\n",
      "Epoch 10/20\n",
      "7634/7634 [==============================] - 3s 388us/step - loss: 0.1762 - acc: 0.9577 - val_loss: 1.4320 - val_acc: 0.7129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa84b0c6550>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_based_model()\n",
    "\n",
    "\n",
    "callback_list = [callbacks.EarlyStopping(patience=8),\n",
    "                 callbacks.ModelCheckpoint('best_based_model.h5', save_best_only=True)]\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20, callbacks=callback_list, batch_size=16, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.调整参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(dropout=0.5):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Embedding(max_featuers, 512, input_length=max_len))\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(dropout))\n",
    "    \n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(dropout))\n",
    "    \n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(46, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7634 samples, validate on 1348 samples\n",
      "Epoch 1/20\n",
      "7634/7634 [==============================] - 18s 2ms/step - loss: 3.4759 - sparse_categorical_accuracy: 0.1969 - val_loss: 2.8408 - val_sparse_categorical_accuracy: 0.3984\n",
      "Epoch 2/20\n",
      "7634/7634 [==============================] - 17s 2ms/step - loss: 2.2078 - sparse_categorical_accuracy: 0.4700 - val_loss: 1.8516 - val_sparse_categorical_accuracy: 0.5364\n",
      "Epoch 3/20\n",
      "7634/7634 [==============================] - 17s 2ms/step - loss: 1.8520 - sparse_categorical_accuracy: 0.5400 - val_loss: 1.6885 - val_sparse_categorical_accuracy: 0.5645\n",
      "Epoch 4/20\n",
      "7634/7634 [==============================] - 16s 2ms/step - loss: 1.6485 - sparse_categorical_accuracy: 0.5849 - val_loss: 1.6602 - val_sparse_categorical_accuracy: 0.5809\n",
      "Epoch 5/20\n",
      "7634/7634 [==============================] - 18s 2ms/step - loss: 1.5075 - sparse_categorical_accuracy: 0.6180 - val_loss: 1.6275 - val_sparse_categorical_accuracy: 0.6098\n",
      "Epoch 6/20\n",
      "7634/7634 [==============================] - 18s 2ms/step - loss: 1.4243 - sparse_categorical_accuracy: 0.6447 - val_loss: 1.5509 - val_sparse_categorical_accuracy: 0.6261\n",
      "Epoch 7/20\n",
      "7634/7634 [==============================] - 17s 2ms/step - loss: 1.2934 - sparse_categorical_accuracy: 0.6768 - val_loss: 1.5114 - val_sparse_categorical_accuracy: 0.6424\n",
      "Epoch 8/20\n",
      "7634/7634 [==============================] - 17s 2ms/step - loss: 1.1879 - sparse_categorical_accuracy: 0.7025 - val_loss: 1.4534 - val_sparse_categorical_accuracy: 0.6706\n",
      "Epoch 9/20\n",
      "7634/7634 [==============================] - 16s 2ms/step - loss: 1.1050 - sparse_categorical_accuracy: 0.7222 - val_loss: 1.4207 - val_sparse_categorical_accuracy: 0.6721\n",
      "Epoch 10/20\n",
      "7634/7634 [==============================] - 17s 2ms/step - loss: 1.0093 - sparse_categorical_accuracy: 0.7435 - val_loss: 1.3601 - val_sparse_categorical_accuracy: 0.6840\n",
      "Epoch 11/20\n",
      "7634/7634 [==============================] - 16s 2ms/step - loss: 0.9710 - sparse_categorical_accuracy: 0.7562 - val_loss: 1.3266 - val_sparse_categorical_accuracy: 0.6899\n",
      "Epoch 12/20\n",
      "7634/7634 [==============================] - 15s 2ms/step - loss: 0.9320 - sparse_categorical_accuracy: 0.7671 - val_loss: 1.3298 - val_sparse_categorical_accuracy: 0.6921\n",
      "Epoch 13/20\n",
      "7634/7634 [==============================] - 17s 2ms/step - loss: 0.8661 - sparse_categorical_accuracy: 0.7798 - val_loss: 1.3053 - val_sparse_categorical_accuracy: 0.6973\n",
      "Epoch 14/20\n",
      "7634/7634 [==============================] - 15s 2ms/step - loss: 0.8259 - sparse_categorical_accuracy: 0.7883 - val_loss: 1.3658 - val_sparse_categorical_accuracy: 0.6818\n",
      "Epoch 15/20\n",
      "7634/7634 [==============================] - 15s 2ms/step - loss: 0.8249 - sparse_categorical_accuracy: 0.7864 - val_loss: 1.3313 - val_sparse_categorical_accuracy: 0.6958\n",
      "Epoch 16/20\n",
      "7634/7634 [==============================] - 15s 2ms/step - loss: 0.7886 - sparse_categorical_accuracy: 0.7960 - val_loss: 1.3467 - val_sparse_categorical_accuracy: 0.7003\n",
      "Epoch 17/20\n",
      "7634/7634 [==============================] - 15s 2ms/step - loss: 0.7431 - sparse_categorical_accuracy: 0.8040 - val_loss: 1.3598 - val_sparse_categorical_accuracy: 0.6958\n",
      "Epoch 18/20\n",
      "7634/7634 [==============================] - 15s 2ms/step - loss: 0.7337 - sparse_categorical_accuracy: 0.8139 - val_loss: 1.3726 - val_sparse_categorical_accuracy: 0.7010\n",
      "Epoch 19/20\n",
      "7634/7634 [==============================] - 15s 2ms/step - loss: 0.6931 - sparse_categorical_accuracy: 0.8140 - val_loss: 1.3841 - val_sparse_categorical_accuracy: 0.6929\n",
      "Epoch 20/20\n",
      "7634/7634 [==============================] - 15s 2ms/step - loss: 0.7050 - sparse_categorical_accuracy: 0.8133 - val_loss: 1.3131 - val_sparse_categorical_accuracy: 0.7055\n",
      "2246/2246 [==============================] - 2s 765us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3704577141963046, 0.70124666073018704]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "\n",
    "\n",
    "callback_list = [callbacks.EarlyStopping(patience=8),\n",
    "                 callbacks.ModelCheckpoint('best_model.h5', save_best_only=True)]\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20, callbacks=callback_list, batch_size=32, validation_split=0.15)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加了Embedding层效果反而不如书上的例子，我们再试试书本上的例子吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    \n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorize\n",
      "Training data shape:(8982, 10000), test data shape:(2246, 10000)\n"
     ]
    }
   ],
   "source": [
    "x_train = vectorize_sequences(x_train)\n",
    "x_test = vectorize_sequences(x_test)\n",
    "\n",
    "print('After vectorize\\nTraining data shape:{}, test data shape:{}'.format(x_train.shape, x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_naive_model():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(46, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7634 samples, validate on 1348 samples\n",
      "Epoch 1/20\n",
      "7634/7634 [==============================] - 6s 791us/step - loss: 3.2955 - sparse_categorical_accuracy: 0.4396 - val_loss: 2.5913 - val_sparse_categorical_accuracy: 0.5364\n",
      "Epoch 2/20\n",
      "7634/7634 [==============================] - 3s 393us/step - loss: 2.0406 - sparse_categorical_accuracy: 0.5713 - val_loss: 1.7177 - val_sparse_categorical_accuracy: 0.6387\n",
      "Epoch 3/20\n",
      "7634/7634 [==============================] - 9s 1ms/step - loss: 1.4246 - sparse_categorical_accuracy: 0.6981 - val_loss: 1.4003 - val_sparse_categorical_accuracy: 0.7047\n",
      "Epoch 4/20\n",
      "7634/7634 [==============================] - 7s 945us/step - loss: 1.1209 - sparse_categorical_accuracy: 0.7588 - val_loss: 1.2393 - val_sparse_categorical_accuracy: 0.7300\n",
      "Epoch 5/20\n",
      "7634/7634 [==============================] - 7s 963us/step - loss: 0.9021 - sparse_categorical_accuracy: 0.8070 - val_loss: 1.1404 - val_sparse_categorical_accuracy: 0.7493\n",
      "Epoch 6/20\n",
      "7634/7634 [==============================] - 13s 2ms/step - loss: 0.7233 - sparse_categorical_accuracy: 0.8463 - val_loss: 1.0657 - val_sparse_categorical_accuracy: 0.7663\n",
      "Epoch 7/20\n",
      "7634/7634 [==============================] - 14s 2ms/step - loss: 0.5755 - sparse_categorical_accuracy: 0.8787 - val_loss: 1.0067 - val_sparse_categorical_accuracy: 0.7767\n",
      "Epoch 8/20\n",
      "7634/7634 [==============================] - 6s 833us/step - loss: 0.4553 - sparse_categorical_accuracy: 0.9027 - val_loss: 0.9725 - val_sparse_categorical_accuracy: 0.7878\n",
      "Epoch 9/20\n",
      "7634/7634 [==============================] - 7s 935us/step - loss: 0.3600 - sparse_categorical_accuracy: 0.9225 - val_loss: 0.9450 - val_sparse_categorical_accuracy: 0.8004\n",
      "Epoch 10/20\n",
      "7634/7634 [==============================] - 6s 762us/step - loss: 0.2868 - sparse_categorical_accuracy: 0.9370 - val_loss: 0.9463 - val_sparse_categorical_accuracy: 0.8019\n",
      "Epoch 11/20\n",
      "7634/7634 [==============================] - 4s 546us/step - loss: 0.2316 - sparse_categorical_accuracy: 0.9462 - val_loss: 0.9426 - val_sparse_categorical_accuracy: 0.8064\n",
      "Epoch 12/20\n",
      "7634/7634 [==============================] - 3s 360us/step - loss: 0.1936 - sparse_categorical_accuracy: 0.9535 - val_loss: 0.9399 - val_sparse_categorical_accuracy: 0.8049\n",
      "Epoch 13/20\n",
      "7634/7634 [==============================] - 3s 370us/step - loss: 0.1634 - sparse_categorical_accuracy: 0.9566 - val_loss: 0.9745 - val_sparse_categorical_accuracy: 0.7990\n",
      "Epoch 14/20\n",
      "7634/7634 [==============================] - 3s 439us/step - loss: 0.1439 - sparse_categorical_accuracy: 0.9576 - val_loss: 0.9818 - val_sparse_categorical_accuracy: 0.7990\n",
      "Epoch 15/20\n",
      "7634/7634 [==============================] - 3s 330us/step - loss: 0.1283 - sparse_categorical_accuracy: 0.9604 - val_loss: 0.9858 - val_sparse_categorical_accuracy: 0.8012\n",
      "Epoch 16/20\n",
      "7634/7634 [==============================] - 3s 345us/step - loss: 0.1188 - sparse_categorical_accuracy: 0.9602 - val_loss: 0.9884 - val_sparse_categorical_accuracy: 0.8034\n",
      "Epoch 17/20\n",
      "7634/7634 [==============================] - 3s 339us/step - loss: 0.1131 - sparse_categorical_accuracy: 0.9621 - val_loss: 1.0551 - val_sparse_categorical_accuracy: 0.7953\n",
      "Epoch 18/20\n",
      "7634/7634 [==============================] - 3s 417us/step - loss: 0.1078 - sparse_categorical_accuracy: 0.9627 - val_loss: 1.0449 - val_sparse_categorical_accuracy: 0.7960\n",
      "Epoch 19/20\n",
      "7634/7634 [==============================] - 3s 425us/step - loss: 0.0976 - sparse_categorical_accuracy: 0.9620 - val_loss: 1.0495 - val_sparse_categorical_accuracy: 0.7990\n",
      "Epoch 20/20\n",
      "7634/7634 [==============================] - 3s 353us/step - loss: 0.0949 - sparse_categorical_accuracy: 0.9633 - val_loss: 1.0555 - val_sparse_categorical_accuracy: 0.7953\n",
      "2246/2246 [==============================] - 0s 150us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0788633611089717, 0.79341050756901155]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_naive_model()\n",
    "\n",
    "callback_list = [callbacks.EarlyStopping(patience=8),\n",
    "                 callbacks.ModelCheckpoint('best_naive_model.h5', save_best_only=True)]\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20, callbacks=callback_list, batch_size=512, validation_split=0.15)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 尝试对书本的例子进行调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    reg = regularizers.l2(0.01)\n",
    "    \n",
    "    model.add(layers.Dense(64, activation='relu',kernel_initializer='he_normal',input_shape=(10000,)))\n",
    "    model.add(layers.Dense(64, activation='relu',kernel_initializer='he_normal'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.BatchNormalization(center=False, scale=False))\n",
    "    model.add(layers.Dense(46, activation='softmax',kernel_initializer='he_normal'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7634 samples, validate on 1348 samples\n",
      "Epoch 1/200\n",
      "7634/7634 [==============================] - 8s 1ms/step - loss: 2.3248 - sparse_categorical_accuracy: 0.5317 - val_loss: 2.2482 - val_sparse_categorical_accuracy: 0.7255\n",
      "Epoch 2/200\n",
      "7634/7634 [==============================] - 1s 175us/step - loss: 1.3301 - sparse_categorical_accuracy: 0.7419 - val_loss: 1.4470 - val_sparse_categorical_accuracy: 0.7522\n",
      "Epoch 3/200\n",
      "7634/7634 [==============================] - 1s 176us/step - loss: 0.9740 - sparse_categorical_accuracy: 0.8027 - val_loss: 1.2019 - val_sparse_categorical_accuracy: 0.7737\n",
      "Epoch 4/200\n",
      "7634/7634 [==============================] - 1s 174us/step - loss: 0.7744 - sparse_categorical_accuracy: 0.8385 - val_loss: 1.1152 - val_sparse_categorical_accuracy: 0.7834\n",
      "Epoch 5/200\n",
      "7634/7634 [==============================] - 1s 174us/step - loss: 0.6295 - sparse_categorical_accuracy: 0.8638 - val_loss: 1.0941 - val_sparse_categorical_accuracy: 0.7841\n",
      "Epoch 6/200\n",
      "7634/7634 [==============================] - 2s 203us/step - loss: 0.5230 - sparse_categorical_accuracy: 0.8864 - val_loss: 1.0889 - val_sparse_categorical_accuracy: 0.7841\n",
      "Epoch 7/200\n",
      "7634/7634 [==============================] - 1s 176us/step - loss: 0.4603 - sparse_categorical_accuracy: 0.8999 - val_loss: 1.0619 - val_sparse_categorical_accuracy: 0.7871\n",
      "Epoch 8/200\n",
      "7634/7634 [==============================] - 1s 182us/step - loss: 0.4077 - sparse_categorical_accuracy: 0.9099 - val_loss: 1.0504 - val_sparse_categorical_accuracy: 0.7893\n",
      "Epoch 9/200\n",
      "7634/7634 [==============================] - 1s 170us/step - loss: 0.3513 - sparse_categorical_accuracy: 0.9190 - val_loss: 1.0665 - val_sparse_categorical_accuracy: 0.7938\n",
      "Epoch 10/200\n",
      "7634/7634 [==============================] - 1s 170us/step - loss: 0.3118 - sparse_categorical_accuracy: 0.9289 - val_loss: 1.0712 - val_sparse_categorical_accuracy: 0.7864\n",
      "Epoch 11/200\n",
      "7634/7634 [==============================] - 1s 167us/step - loss: 0.2863 - sparse_categorical_accuracy: 0.9312 - val_loss: 1.0567 - val_sparse_categorical_accuracy: 0.7990\n",
      "Epoch 12/200\n",
      "7634/7634 [==============================] - 1s 168us/step - loss: 0.2736 - sparse_categorical_accuracy: 0.9403 - val_loss: 1.0731 - val_sparse_categorical_accuracy: 0.8034\n",
      "Epoch 13/200\n",
      "7634/7634 [==============================] - 1s 175us/step - loss: 0.2401 - sparse_categorical_accuracy: 0.9437 - val_loss: 1.0843 - val_sparse_categorical_accuracy: 0.7982\n",
      "Epoch 14/200\n",
      "7634/7634 [==============================] - 1s 178us/step - loss: 0.2287 - sparse_categorical_accuracy: 0.9450 - val_loss: 1.0765 - val_sparse_categorical_accuracy: 0.7975\n",
      "Epoch 15/200\n",
      "7634/7634 [==============================] - 1s 172us/step - loss: 0.2236 - sparse_categorical_accuracy: 0.9454 - val_loss: 1.0768 - val_sparse_categorical_accuracy: 0.7975\n",
      "Epoch 16/200\n",
      "7634/7634 [==============================] - 1s 172us/step - loss: 0.2033 - sparse_categorical_accuracy: 0.9502 - val_loss: 1.0835 - val_sparse_categorical_accuracy: 0.8056\n",
      "Epoch 17/200\n",
      "7634/7634 [==============================] - 1s 164us/step - loss: 0.1911 - sparse_categorical_accuracy: 0.9496 - val_loss: 1.0652 - val_sparse_categorical_accuracy: 0.7923\n",
      "Epoch 18/200\n",
      "7634/7634 [==============================] - 1s 165us/step - loss: 0.1987 - sparse_categorical_accuracy: 0.9492 - val_loss: 1.1018 - val_sparse_categorical_accuracy: 0.7938\n",
      "Epoch 19/200\n",
      "7634/7634 [==============================] - 1s 170us/step - loss: 0.1808 - sparse_categorical_accuracy: 0.9518 - val_loss: 1.0997 - val_sparse_categorical_accuracy: 0.7953\n",
      "Epoch 20/200\n",
      "7634/7634 [==============================] - 1s 173us/step - loss: 0.1754 - sparse_categorical_accuracy: 0.9538 - val_loss: 1.1229 - val_sparse_categorical_accuracy: 0.8019\n",
      "Epoch 21/200\n",
      "7634/7634 [==============================] - 1s 171us/step - loss: 0.1691 - sparse_categorical_accuracy: 0.9557 - val_loss: 1.1319 - val_sparse_categorical_accuracy: 0.7945\n",
      "Epoch 22/200\n",
      "7634/7634 [==============================] - 1s 164us/step - loss: 0.1764 - sparse_categorical_accuracy: 0.9531 - val_loss: 1.1406 - val_sparse_categorical_accuracy: 0.8034\n",
      "Epoch 23/200\n",
      "7634/7634 [==============================] - 1s 181us/step - loss: 0.1659 - sparse_categorical_accuracy: 0.9534 - val_loss: 1.1298 - val_sparse_categorical_accuracy: 0.8012\n",
      "Epoch 24/200\n",
      "7634/7634 [==============================] - 1s 185us/step - loss: 0.1612 - sparse_categorical_accuracy: 0.9536 - val_loss: 1.1073 - val_sparse_categorical_accuracy: 0.7967\n",
      "Epoch 25/200\n",
      "7634/7634 [==============================] - 1s 173us/step - loss: 0.1551 - sparse_categorical_accuracy: 0.9553 - val_loss: 1.1580 - val_sparse_categorical_accuracy: 0.8019\n",
      "Epoch 26/200\n",
      "7634/7634 [==============================] - 1s 179us/step - loss: 0.1477 - sparse_categorical_accuracy: 0.9566 - val_loss: 1.1572 - val_sparse_categorical_accuracy: 0.8071\n",
      "Epoch 27/200\n",
      "7634/7634 [==============================] - 1s 172us/step - loss: 0.1478 - sparse_categorical_accuracy: 0.9552 - val_loss: 1.1986 - val_sparse_categorical_accuracy: 0.8042\n",
      "Epoch 28/200\n",
      "7634/7634 [==============================] - 1s 168us/step - loss: 0.1419 - sparse_categorical_accuracy: 0.9583 - val_loss: 1.1755 - val_sparse_categorical_accuracy: 0.8064\n",
      "Epoch 29/200\n",
      "7634/7634 [==============================] - 1s 172us/step - loss: 0.1438 - sparse_categorical_accuracy: 0.9591 - val_loss: 1.1607 - val_sparse_categorical_accuracy: 0.7997\n",
      "Epoch 30/200\n",
      "7634/7634 [==============================] - 1s 176us/step - loss: 0.1453 - sparse_categorical_accuracy: 0.9576 - val_loss: 1.1859 - val_sparse_categorical_accuracy: 0.8019\n",
      "Epoch 31/200\n",
      "7634/7634 [==============================] - 1s 168us/step - loss: 0.1330 - sparse_categorical_accuracy: 0.9591 - val_loss: 1.1863 - val_sparse_categorical_accuracy: 0.8019\n",
      "Epoch 32/200\n",
      "7634/7634 [==============================] - 1s 166us/step - loss: 0.1331 - sparse_categorical_accuracy: 0.9570 - val_loss: 1.1786 - val_sparse_categorical_accuracy: 0.8027\n",
      "Epoch 33/200\n",
      "7634/7634 [==============================] - 1s 188us/step - loss: 0.1336 - sparse_categorical_accuracy: 0.9589 - val_loss: 1.1931 - val_sparse_categorical_accuracy: 0.7953\n",
      "Epoch 34/200\n",
      "7634/7634 [==============================] - 1s 195us/step - loss: 0.1291 - sparse_categorical_accuracy: 0.9603 - val_loss: 1.2248 - val_sparse_categorical_accuracy: 0.8056\n",
      "Epoch 35/200\n",
      "7634/7634 [==============================] - 1s 164us/step - loss: 0.1296 - sparse_categorical_accuracy: 0.9593 - val_loss: 1.1877 - val_sparse_categorical_accuracy: 0.8056\n",
      "Epoch 36/200\n",
      "7634/7634 [==============================] - 2s 296us/step - loss: 0.1285 - sparse_categorical_accuracy: 0.9597 - val_loss: 1.2065 - val_sparse_categorical_accuracy: 0.8034\n",
      "Epoch 37/200\n",
      "7634/7634 [==============================] - 1s 173us/step - loss: 0.1290 - sparse_categorical_accuracy: 0.9590 - val_loss: 1.2306 - val_sparse_categorical_accuracy: 0.8027\n",
      "Epoch 38/200\n",
      "7634/7634 [==============================] - 1s 170us/step - loss: 0.1239 - sparse_categorical_accuracy: 0.9597 - val_loss: 1.2083 - val_sparse_categorical_accuracy: 0.8049\n",
      "Epoch 39/200\n",
      "7634/7634 [==============================] - 1s 167us/step - loss: 0.1234 - sparse_categorical_accuracy: 0.9606 - val_loss: 1.2333 - val_sparse_categorical_accuracy: 0.7990\n",
      "Epoch 40/200\n",
      "7634/7634 [==============================] - 1s 173us/step - loss: 0.1209 - sparse_categorical_accuracy: 0.9616 - val_loss: 1.2485 - val_sparse_categorical_accuracy: 0.8012\n",
      "Epoch 41/200\n",
      "7634/7634 [==============================] - 1s 177us/step - loss: 0.1147 - sparse_categorical_accuracy: 0.9631 - val_loss: 1.2593 - val_sparse_categorical_accuracy: 0.8049\n",
      "Epoch 42/200\n",
      "7634/7634 [==============================] - 1s 168us/step - loss: 0.1110 - sparse_categorical_accuracy: 0.9624 - val_loss: 1.2866 - val_sparse_categorical_accuracy: 0.8042\n",
      "Epoch 43/200\n",
      "7634/7634 [==============================] - 1s 180us/step - loss: 0.1222 - sparse_categorical_accuracy: 0.9587 - val_loss: 1.2487 - val_sparse_categorical_accuracy: 0.8093\n",
      "Epoch 44/200\n",
      "7634/7634 [==============================] - 1s 174us/step - loss: 0.1210 - sparse_categorical_accuracy: 0.9586 - val_loss: 1.2545 - val_sparse_categorical_accuracy: 0.8042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200\n",
      "7634/7634 [==============================] - 1s 166us/step - loss: 0.1105 - sparse_categorical_accuracy: 0.9632 - val_loss: 1.2840 - val_sparse_categorical_accuracy: 0.8042\n",
      "Epoch 46/200\n",
      "7634/7634 [==============================] - 1s 169us/step - loss: 0.1172 - sparse_categorical_accuracy: 0.9598 - val_loss: 1.2637 - val_sparse_categorical_accuracy: 0.8056\n",
      "Epoch 47/200\n",
      "7634/7634 [==============================] - 1s 169us/step - loss: 0.1112 - sparse_categorical_accuracy: 0.9631 - val_loss: 1.2755 - val_sparse_categorical_accuracy: 0.8027\n",
      "Epoch 48/200\n",
      "7634/7634 [==============================] - 1s 172us/step - loss: 0.1132 - sparse_categorical_accuracy: 0.9611 - val_loss: 1.3092 - val_sparse_categorical_accuracy: 0.7997\n",
      "Epoch 49/200\n",
      "7634/7634 [==============================] - 1s 170us/step - loss: 0.1086 - sparse_categorical_accuracy: 0.9615 - val_loss: 1.2921 - val_sparse_categorical_accuracy: 0.8027\n",
      "Epoch 50/200\n",
      "7634/7634 [==============================] - 1s 173us/step - loss: 0.1095 - sparse_categorical_accuracy: 0.9608 - val_loss: 1.2780 - val_sparse_categorical_accuracy: 0.8027\n",
      "Epoch 51/200\n",
      "7634/7634 [==============================] - 1s 169us/step - loss: 0.1081 - sparse_categorical_accuracy: 0.9636 - val_loss: 1.3012 - val_sparse_categorical_accuracy: 0.8027\n",
      "Epoch 52/200\n",
      "7634/7634 [==============================] - 1s 169us/step - loss: 0.1047 - sparse_categorical_accuracy: 0.9629 - val_loss: 1.3114 - val_sparse_categorical_accuracy: 0.7967\n",
      "Epoch 53/200\n",
      "7634/7634 [==============================] - 1s 164us/step - loss: 0.1130 - sparse_categorical_accuracy: 0.9599 - val_loss: 1.3684 - val_sparse_categorical_accuracy: 0.8064\n",
      "Epoch 54/200\n",
      "7634/7634 [==============================] - 1s 167us/step - loss: 0.1103 - sparse_categorical_accuracy: 0.9640 - val_loss: 1.3155 - val_sparse_categorical_accuracy: 0.8056\n",
      "Epoch 55/200\n",
      "7634/7634 [==============================] - 1s 171us/step - loss: 0.1005 - sparse_categorical_accuracy: 0.9635 - val_loss: 1.2855 - val_sparse_categorical_accuracy: 0.8012\n",
      "Epoch 56/200\n",
      "7634/7634 [==============================] - 1s 159us/step - loss: 0.1080 - sparse_categorical_accuracy: 0.9624 - val_loss: 1.3084 - val_sparse_categorical_accuracy: 0.8019\n",
      "Epoch 57/200\n",
      "7634/7634 [==============================] - 1s 162us/step - loss: 0.1025 - sparse_categorical_accuracy: 0.9641 - val_loss: 1.3183 - val_sparse_categorical_accuracy: 0.8004\n",
      "Epoch 58/200\n",
      "7634/7634 [==============================] - 1s 163us/step - loss: 0.1048 - sparse_categorical_accuracy: 0.9637 - val_loss: 1.3418 - val_sparse_categorical_accuracy: 0.8004\n",
      "2246/2246 [==============================] - 0s 160us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3954193265121746, 0.79608192347248852]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "\n",
    "callback_list = [callbacks.EarlyStopping(patience=50),\n",
    "                 callbacks.ModelCheckpoint('best_model.h5', save_best_only=True)]\n",
    "\n",
    "model.fit(x_train, y_train, epochs=200, callbacks=callback_list, batch_size=64, validation_split=0.15)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "+ 调参好累，调了半天也"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

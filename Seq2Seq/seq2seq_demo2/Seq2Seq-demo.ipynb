{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Seq2Seq示例\n",
    "\n",
    "+ 任务很简单，将数字转为中文大写金额，例如 11288 -> 壹万壹仟零捌拾捌元整\n",
    "+ 我们将尝试利用seq2seq来解决这一问题，整个示例包括以下部分：\n",
    "    + 建立数据集\n",
    "    + 设计seq2seq模型\n",
    "    + 对比不同seq2seq模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立数据集\n",
    "\n",
    "+ 找到一个将数字转中文的python代码 http://blog.csdn.net/zzcwing/article/details/8763212 我们利用这个来建立数据集\n",
    "+ 为了让事情变得简单一点，我们对数据集做一些约束：\n",
    "    + 数据集中的数字大小不超过 10w，也就是说范围在[0, 99999]\n",
    "    + 都是整数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "#set_session(tf.Session(config=config))\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Embedding, Bidirectional, Dense, Concatenate, LSTM\n",
    "from keras.models import Model, load_model\n",
    "from keras import callbacks\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是数字转中文大写的代码，感谢作者"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Apr 06 00:28:24 2013\n",
    "\n",
    "@author: zzcwing\n",
    "\"\"\"\n",
    "#算法说明：要求字符串输入，现将字符串差费为整数部分和小数部分生成list[整数部分,小数部分]\n",
    "#将整数部分拆分为：[亿，万，仟]三组字符串组成的List:['0000','0000','0000']（根据实际输入生成阶梯List）\n",
    "#例如：600190000010.70整数部分拆分为：['600','1900','0010']\n",
    "#然后对list中每个字符串分组进行大写化再合并\n",
    "#最后处理小数部分的大写化\n",
    "\n",
    "class cnumber:\n",
    "    cdict={}\n",
    "    gdict={}\n",
    "    xdict={}\n",
    "    def __init__(self):\n",
    "        self.cdict={1:u'',2:u'拾',3:u'佰',4:u'仟'}\n",
    "        self.xdict={1:u'元',2:u'万',3:u'亿',4:u'兆'} #数字标识符\n",
    "        self.gdict={0:u'零',1:u'壹',2:u'贰',3:u'叁',4:u'肆',5:u'伍',6:u'陆',7:u'柒',8:u'捌',9:u'玖'}       \n",
    "\n",
    "    def csplit(self,cdata): #拆分函数，将整数字符串拆分成[亿，万，仟]的list\n",
    "        g=len(cdata)%4\n",
    "        csdata=[]\n",
    "        lx=len(cdata)-1\n",
    "        if g>0:\n",
    "            csdata.append(cdata[0:g])\n",
    "        k=g\n",
    "        while k<=lx:\n",
    "            csdata.append(cdata[k:k+4])\n",
    "            k+=4\n",
    "        return csdata\n",
    "    \n",
    "    def cschange(self,cki): #对[亿，万，仟]的list中每个字符串分组进行大写化再合并\n",
    "        \n",
    "        lenki=len(cki)\n",
    "        i=0\n",
    "        lk=lenki\n",
    "        chk=u''\n",
    "        for i in range(lenki):\n",
    "            if int(cki[i])==0:\n",
    "                if i<lenki-1:\n",
    "                    if int(cki[i+1])!=0:\n",
    "                        chk=chk+self.gdict[int(cki[i])]                    \n",
    "            else:\n",
    "                chk=chk+self.gdict[int(cki[i])]+self.cdict[lk]\n",
    "            lk-=1\n",
    "        return chk\n",
    "        \n",
    "    def cwchange(self,data):\n",
    "        if not '.' in data:\n",
    "            data = data + '.00'\n",
    "        cdata=str(data).split('.')\n",
    "        \n",
    "        cki=cdata[0]\n",
    "        ckj=cdata[1]\n",
    "        i=0\n",
    "        chk=u''\n",
    "        cski=self.csplit(cki) #分解字符数组[亿，万，仟]三组List:['0000','0000','0000']\n",
    "        ikl=len(cski) #获取拆分后的List长度\n",
    "        #大写合并\n",
    "        for i in range(ikl):\n",
    "            if self.cschange(cski[i])=='': #有可能一个字符串全是0的情况\n",
    "                chk=chk+self.cschange(cski[i]) #此时不需要将数字标识符引入\n",
    "            else:\n",
    "                chk=chk+self.cschange(cski[i])+self.xdict[ikl-i] #合并：前字符串大写+当前字符串大写+标识符\n",
    "        #处理小数部分\n",
    "        lenkj=len(ckj)\n",
    "        if lenkj==1: #若小数只有1位\n",
    "            if int(ckj[0])==0: \n",
    "                chk=chk+u'整'\n",
    "            else:\n",
    "                chk=chk+self.gdict[int(ckj[0])]+u'角整'\n",
    "        else: #若小数有两位的四种情况\n",
    "            if int(ckj[0])==0 and int(ckj[1])!=0:\n",
    "                chk=chk+u'零'+self.gdict[int(ckj[1])]+u'分'\n",
    "            elif int(ckj[0])==0 and int(ckj[1])==0:\n",
    "                chk=chk+u'整'\n",
    "            elif int(ckj[0])!=0 and int(ckj[1])!=0:\n",
    "                chk=chk+self.gdict[int(ckj[0])]+u'角'+self.gdict[int(ckj[1])]+u'分'\n",
    "            else:\n",
    "                chk=chk+self.gdict[int(ckj[0])]+u'角整'\n",
    "        return chk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成数据，范围在[1, 99999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt=cnumber()\n",
    "\n",
    "# 生成数据，并写入文件中\n",
    "num_range = range(1, 100000)\n",
    "data_path = 'dataset.txt'\n",
    "with open(data_path, 'w') as f:\n",
    "    for num in num_range:\n",
    "        num_str = str(num)\n",
    "        ch_num = pt.cwchange(num_str)\n",
    "        f.write(num_str + '\\t' + ch_num + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 向量化数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72608\t柒万贰仟陆佰零捌元整\n",
      "17338\t壹万柒仟叁佰叁拾捌元整\n",
      "99815\t玖万玖仟捌佰壹拾伍元整\n",
      "38187\t叁万捌仟壹佰捌拾柒元整\n",
      "79028\t柒万玖仟零贰拾捌元整\n",
      "95661\t玖万伍仟陆佰陆拾壹元整\n",
      "29591\t贰万玖仟伍佰玖拾壹元整\n",
      "11372\t壹万壹仟叁佰柒拾贰元整\n",
      "31327\t叁万壹仟叁佰贰拾柒元整\n",
      "84890\t捌万肆仟捌佰玖拾元整\n"
     ]
    }
   ],
   "source": [
    "num_samples = 50000\n",
    "\n",
    "data_path = 'dataset.txt'\n",
    "# 读入数据\n",
    "with open(data_path, 'r') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    \n",
    "# 打乱顺序\n",
    "random.shuffle(lines)\n",
    "# 显示部分数据\n",
    "for line in lines[:10]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nunmber of samples: 50000\n",
      "Max sequence length of input: 5\n",
      "Max sequence length of outputs: 13\n"
     ]
    }
   ],
   "source": [
    "input_texts = [] #输入数据，也就是数字字符串\n",
    "target_texts = [] #目标数据，也就是中文大写字符串\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "# 分割数据为 input_texts 和 target_texts\n",
    "# 且统计一些信息\n",
    "for line in lines[: min(num_samples, len(lines)-1)]:\n",
    "    try:\n",
    "        input_text, target_text = line.split('\\t')\n",
    "    except ValueError:\n",
    "        print('Error line:', line)\n",
    "        input_text = ''\n",
    "        target_text = ''\n",
    "        \n",
    "    # 计算 input_texts 中的 tokens数量\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "            \n",
    "    # 计算 target_texts 中的 tokens数量\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "        \n",
    "    # 用 '始'作为开始字符\n",
    "    # 用 '终'作为结束字符\n",
    "    target_text = '始' + target_text + '终'\n",
    "    \n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    \n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "\n",
    "max_encoder_seq_length = max([ len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([ len(txt) for txt in target_texts])\n",
    "\n",
    "print('Nunmber of samples:', len(input_texts))\n",
    "print('Max sequence length of input:', max_encoder_seq_length)\n",
    "print('Max sequence length of outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立字典，用于字符转数字\n",
    "\n",
    "# '[pad]'表示填充字符\n",
    "input_token_index = dict( [(char, i) for i, char in enumerate(['pad']+input_characters)])\n",
    "\n",
    "# '始'表示开始字符，'终'表示终止字符，'空'表示填充字符\n",
    "special_characters = ['空', '始', '终']\n",
    "target_token_index = dict([ (char,i ) for i, char in enumerate(special_characters + target_characters)])\n",
    "\n",
    "num_encoder_tokens = len(input_token_index)\n",
    "num_decoder_tokens = len(target_token_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def characters2index(text, char_index):\n",
    "    # 将字符串向量化\n",
    "    return [char_index.get(char) for char in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建向量化的数据\n",
    "encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length), dtype=np.int32)\n",
    "decoder_input_data = np.zeros((len(target_texts), max_decoder_seq_length), dtype=np.int32)\n",
    "# decoder_target_data 需要 one-hot 编码\n",
    "decoder_target_data = np.zeros((len(target_texts), max_decoder_seq_length, num_decoder_tokens), dtype=np.float32)\n",
    "\n",
    "# 填充数据\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    input_indexs = characters2index(input_text, input_token_index)\n",
    "    encoder_input_data[i, :len(input_indexs)] = input_indexs\n",
    "    \n",
    "    target_indexs = characters2index(target_text, target_token_index)\n",
    "    decoder_input_data[i, :len(target_indexs)] = target_indexs\n",
    "    \n",
    "    # decoder_target_data 做one-hot编码，且偏移一位\n",
    "    for t, index in enumerate(decoder_input_data[i, 1:]):\n",
    "        decoder_target_data[i, t, index] = 1.0\n",
    "    decoder_target_data[i, -1, 0] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 设计模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数\n",
    "encoder_embedding_dim = 10\n",
    "decoder_embedding_dim = 20\n",
    "latent_dim = 128\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单向模型\n",
    "+ 编码器和解码器都是单向lstm\n",
    "    + 编码器：encoder_input -> encoder_embedding -> encoder_lstm -> ...\n",
    "    + 解码器：decoder_input -> decoder_embbeding -> decoder_lstm -> decoder_dense -> ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_basic_model():\n",
    "    rnn = layers.LSTM\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=(None,), name='encoder_inputs')\n",
    "    encoder_embedding = Embedding(num_encoder_tokens, encoder_embedding_dim, name='encoder_embedding')(encoder_inputs)\n",
    "    encoder_lstm = rnn(latent_dim, return_state=True, return_sequences=True, dropout=0.2, recurrent_dropout=0.5, name='encoder_lstm')\n",
    "    _, *encoder_states = encoder_lstm(encoder_embedding)\n",
    "    \n",
    "    # Decoder\n",
    "    decoder_inputs = Input(shape=(None,), name='decoder_inputs')\n",
    "    decoder_embedding = Embedding(num_decoder_tokens, decoder_embedding_dim, name='decoder_embedding')(decoder_inputs)\n",
    "    decoder_lstm = rnn(latent_dim, return_state=True, return_sequences=True, dropout=0.2, recurrent_dropout=0.5, name='decoder_lstm')\n",
    "    rnn_outputs, *decoder_states = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
    "    decoder_outputs = decoder_dense(rnn_outputs)\n",
    "    \n",
    "    basic_model = Model([encoder_inputs, decoder_inputs], [decoder_outputs])\n",
    "    basic_model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    return basic_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练单向模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 49s 1ms/step - loss: 1.2564 - val_loss: 0.7960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nls3/anaconda2/envs/keras/lib/python3.6/site-packages/keras/engine/topology.py:2364: UserWarning: Layer decoder_lstm was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'encoder_lstm/while/Exit_2:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'encoder_lstm/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 43s 1ms/step - loss: 0.7724 - val_loss: 0.6788\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 47s 1ms/step - loss: 0.5891 - val_loss: 0.3697\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 46s 1ms/step - loss: 0.3621 - val_loss: 0.1546\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 43s 1ms/step - loss: 0.2083 - val_loss: 0.0564\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 41s 1ms/step - loss: 0.1248 - val_loss: 0.0201\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 40s 1ms/step - loss: 0.0772 - val_loss: 0.0079\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 42s 1ms/step - loss: 0.0491 - val_loss: 0.0033\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 47s 1ms/step - loss: 0.0334 - val_loss: 0.0018\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 45s 1ms/step - loss: 0.0240 - val_loss: 0.0011\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 40s 1ms/step - loss: 0.0186 - val_loss: 7.0768e-04\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 46s 1ms/step - loss: 0.0144 - val_loss: 4.9915e-04\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 45s 1ms/step - loss: 0.0118 - val_loss: 3.6997e-04\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 46s 1ms/step - loss: 0.0095 - val_loss: 2.7497e-04\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 42s 1ms/step - loss: 0.0078 - val_loss: 2.3511e-04\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 46s 1ms/step - loss: 0.0067 - val_loss: 1.9679e-04\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 46s 1ms/step - loss: 0.0058 - val_loss: 1.5624e-04\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 42s 1ms/step - loss: 0.0052 - val_loss: 1.6106e-04\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 44s 1ms/step - loss: 0.0047 - val_loss: 1.1229e-04\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 46s 1ms/step - loss: 0.0041 - val_loss: 7.0554e-05\n"
     ]
    }
   ],
   "source": [
    "# 回调函数\n",
    "callback_list = [callbacks.ModelCheckpoint('basic_model_best.h', save_best_only=True)]\n",
    "# 获取模型\n",
    "basic_model = build_basic_model()\n",
    "# 训练\n",
    "basic_model_hist = basic_model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "                batch_size=batch_size, epochs=epochs,\n",
    "                validation_split=0.2, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试单向模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立推理模型\n",
    "def build_basic_inference_model(model_path):\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # encoder\n",
    "    encoder_inputs = Input(shape=(None,))\n",
    "    # encoder_embedding\n",
    "    encoder_embedding = model.get_layer('encoder_embedding')(encoder_inputs)\n",
    "    # get encoder states\n",
    "    _, *encoder_states = model.get_layer('encoder_lstm')(encoder_embedding)\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    # decoder\n",
    "    # decoder inputs\n",
    "    decoder_inputs = Input(shape=(None,))\n",
    "    # decoder input states \n",
    "    decoder_state_h = Input(shape=(latent_dim,))\n",
    "    decoder_state_c = Input(shape=(latent_dim,))\n",
    "    decoder_states_inputs = [decoder_state_h, decoder_state_c]\n",
    "    \n",
    "    # decoder embedding\n",
    "    decoder_embedding = model.get_layer('decoder_embedding')(decoder_inputs)\n",
    "    # get rnn outputs and decoder states\n",
    "    rnn_outputs, *decoder_states = model.get_layer('decoder_lstm')(decoder_embedding, initial_state=decoder_states_inputs)\n",
    "    decoder_outputs = model.get_layer('decoder_dense')(rnn_outputs)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs]+decoder_states)\n",
    "    \n",
    "    return encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict([(i, char) for char, i in input_token_index.items()])\n",
    "reverse_target_word_index = dict([(i, char) for char, i in target_token_index.items()])\n",
    "\n",
    "def decode_sequence(input_seq, encoder_model, decoder_model):\n",
    "    # get encoder states\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # create a empty sequence\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = target_token_index['始']\n",
    "    \n",
    "    # 进行句子的恢复\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        output, *decoder_states = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output[0, -1, :])\n",
    "        sampled_word = reverse_target_word_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_word\n",
    "        \n",
    "        if sampled_word == '终' or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "            \n",
    "        # update target_seq\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        \n",
    "        # update states\n",
    "        states_value = decoder_states\n",
    "        \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立一些测试用的样本\n",
    "test_input_texts = [line.split('\\t')[0] for line in lines[-20:]]\n",
    "test_input_data = np.zeros((len(test_input_texts), max_encoder_seq_length), np.int32)\n",
    "for i, test_text in enumerate(test_input_texts):\n",
    "    test_indexs = characters2index(test_text, input_token_index)\n",
    "    test_input_data[i, :len(test_indexs)] = test_indexs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入模型\n",
    "model_path = 'basic_model_best.h'\n",
    "inference_encoder_model, inference_decoder_model = build_basic_inference_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: 59798\n",
      "Decoded sentence: 伍万玖仟柒佰玖拾捌元整终\n",
      "-\n",
      "Input sentence: 28307\n",
      "Decoded sentence: 贰万捌仟叁佰零柒元整终\n",
      "-\n",
      "Input sentence: 49323\n",
      "Decoded sentence: 肆万玖仟叁佰贰拾叁元整终\n",
      "-\n",
      "Input sentence: 24169\n",
      "Decoded sentence: 贰万肆仟壹佰陆拾玖元整终\n",
      "-\n",
      "Input sentence: 95323\n",
      "Decoded sentence: 玖万伍仟叁佰贰拾叁元整终\n",
      "-\n",
      "Input sentence: 50104\n",
      "Decoded sentence: 伍万零壹佰零肆元整终\n",
      "-\n",
      "Input sentence: 34650\n",
      "Decoded sentence: 叁万肆仟陆佰伍拾元整终\n",
      "-\n",
      "Input sentence: 60256\n",
      "Decoded sentence: 陆万零贰佰伍拾陆元整终\n",
      "-\n",
      "Input sentence: 42183\n",
      "Decoded sentence: 肆万贰仟壹佰捌拾叁元整终\n",
      "-\n",
      "Input sentence: 68802\n",
      "Decoded sentence: 陆万捌仟捌佰零贰元整终\n",
      "-\n",
      "Input sentence: 63819\n",
      "Decoded sentence: 陆万叁仟捌佰壹拾玖元整终\n",
      "-\n",
      "Input sentence: 32531\n",
      "Decoded sentence: 叁万贰仟伍佰叁拾壹元整终\n",
      "-\n",
      "Input sentence: 25678\n",
      "Decoded sentence: 贰万伍仟陆佰柒拾捌元整终\n",
      "-\n",
      "Input sentence: 42272\n",
      "Decoded sentence: 肆万贰仟贰佰柒拾贰元整终\n",
      "-\n",
      "Input sentence: 48908\n",
      "Decoded sentence: 肆万捌仟玖佰零捌元整终\n",
      "-\n",
      "Input sentence: 74546\n",
      "Decoded sentence: 柒万肆仟伍佰肆拾陆元整终\n",
      "-\n",
      "Input sentence: 11869\n",
      "Decoded sentence: 壹万壹仟捌佰陆拾玖元整终\n",
      "-\n",
      "Input sentence: 75803\n",
      "Decoded sentence: 柒万伍仟捌佰零叁元整终\n",
      "-\n",
      "Input sentence: 75727\n",
      "Decoded sentence: 柒万伍仟柒佰贰拾柒元整终\n",
      "-\n",
      "Input sentence: 67230\n",
      "Decoded sentence: 陆万柒仟贰佰叁拾元整终\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "for seq_index in range(len(test_input_texts)):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = test_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq, inference_encoder_model, inference_decoder_model)\n",
    "    print('-')\n",
    "    print('Input sentence:', test_input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 双向编码器模型\n",
    "+ 编码器使用双向的lstm，解码器使用单向的lstm\n",
    "    + 编码器：encoder_input -> encoder_embedding -> bidi_encoder_lstm -> ...\n",
    "    + 解码器：decoder_input -> decoder_embbeding -> decoder_lstm -> decoder_dense -> ...\n",
    "    \n",
    "+ 由于编码器是双向的，其状态包括 `forward_h, forward_c, backward_h, backward_c`，每个状态的`shape=(?, latent_dim)`，需要将foward 和 backward的状态进行合并，合并成为 `state_h, state_c`，其`shape=(?, latent_dim*2)`\n",
    "+ 因此，解码器为了能够接收编码器的状态，解码器的latent_dim要与`state_h, state_c`一致，因此解码器的LSTM单元数量是两倍的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bidi_encoder_model():\n",
    "    rnn = layers.LSTM\n",
    "    \n",
    "    # Encoder\n",
    "    # encoder inputs\n",
    "    encoder_inputs = Input(shape=(None,), name='encoder_inputs')\n",
    "    # encoder embedding\n",
    "    encoder_embedding = Embedding(num_encoder_tokens, encoder_embedding_dim,name='encoder_embedding')(encoder_inputs)\n",
    "    # encoder lstm\n",
    "    bidi_encoder_lstm = Bidirectional(rnn(latent_dim, return_state=True, dropout=0.2,recurrent_dropout=0.5), name='encoder_lstm')\n",
    "    _, forward_h, forward_c, backward_h, backward_c = bidi_encoder_lstm(encoder_embedding)\n",
    "    state_h = Concatenate()([forward_h, backward_h])\n",
    "    state_c = Concatenate()([forward_c, backward_c])\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    # Decoder\n",
    "    # decoder inputs\n",
    "    decoder_inputs = Input(shape=(None,), name='decoder_inputs')\n",
    "    # decoder embeddding\n",
    "    decoder_embedding = Embedding(num_decoder_tokens, decoder_embedding_dim, name='decoder_embedding')(decoder_inputs)\n",
    "    # decoder lstm, number of units is 2*latent_dim\n",
    "    # NOTE THIS : latent_dim*2 for matching encoder_states\n",
    "    decoder_lstm = rnn(latent_dim*2, return_state=True, \n",
    "                       return_sequences=True, dropout=0.2,\n",
    "                       recurrent_dropout=0.5, name='decoder_lstm')\n",
    "    # get outputs and decoder states\n",
    "    rnn_outputs, *decoder_states = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "    # decoder dense\n",
    "    decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
    "    decoder_outputs = decoder_dense(rnn_outputs)\n",
    "    \n",
    "    bidi_encoder_model = Model([encoder_inputs,decoder_inputs], [decoder_outputs])\n",
    "    bidi_encoder_model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    \n",
    "    return bidi_encoder_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练双向编码器模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 66s 2ms/step - loss: 1.1616 - val_loss: 0.7842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nls3/anaconda2/envs/keras/lib/python3.6/site-packages/keras/engine/topology.py:2364: UserWarning: Layer decoder_lstm was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'concatenate_1/concat:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'concatenate_2/concat:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 53s 1ms/step - loss: 0.7496 - val_loss: 0.5850\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 58s 1ms/step - loss: 0.4799 - val_loss: 0.2103\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 59s 1ms/step - loss: 0.1990 - val_loss: 0.0308\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 0.0709 - val_loss: 0.0047\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 57s 1ms/step - loss: 0.0335 - val_loss: 0.0016\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 60s 2ms/step - loss: 0.0200 - val_loss: 7.4840e-04\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 54s 1ms/step - loss: 0.0131 - val_loss: 4.8027e-04\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 59s 1ms/step - loss: 0.0095 - val_loss: 3.4750e-04\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 59s 1ms/step - loss: 0.0074 - val_loss: 2.6341e-04\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 54s 1ms/step - loss: 0.0059 - val_loss: 1.6931e-04\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 0.0045 - val_loss: 1.1235e-04\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 56s 1ms/step - loss: 0.0039 - val_loss: 1.6833e-04\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 59s 1ms/step - loss: 0.0033 - val_loss: 8.8947e-05\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 57s 1ms/step - loss: 0.0029 - val_loss: 5.1783e-05\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 59s 1ms/step - loss: 0.0022 - val_loss: 8.2367e-05\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 60s 2ms/step - loss: 0.0022 - val_loss: 4.1262e-05\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 56s 1ms/step - loss: 0.0019 - val_loss: 7.5177e-05\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 61s 2ms/step - loss: 0.0017 - val_loss: 9.4143e-05\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 61s 2ms/step - loss: 0.0016 - val_loss: 3.8348e-05\n"
     ]
    }
   ],
   "source": [
    "# 回调函数\n",
    "callback_list = [callbacks.ModelCheckpoint('bidi_encoder_model_best.h', save_best_only=True)]\n",
    "# 获取模型\n",
    "bidi_encoder_model = build_bidi_encoder_model()\n",
    "# 训练\n",
    "bidi_encoder_model_hist = bidi_encoder_model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "                batch_size=batch_size, epochs=epochs,\n",
    "                validation_split=0.2, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bidi_encoder_inference_model(model_path):\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # encoder\n",
    "    encoder_inputs = Input(shape=(None,))\n",
    "    # encoder_embedding\n",
    "    encoder_embedding = model.get_layer('encoder_embedding')(encoder_inputs)\n",
    "    # get encoder states\n",
    "    _, forward_h, forward_c, backward_h, backward_c = model.get_layer('encoder_lstm')(encoder_embedding)\n",
    "    state_h = Concatenate()([forward_h, backward_h])\n",
    "    state_c = Concatenate()([forward_c, backward_c])\n",
    "    encoder_states = [state_h, state_c]\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    # decoder\n",
    "    # decoder inputs\n",
    "    decoder_inputs = Input(shape=(None,))\n",
    "    # decoder input states \n",
    "    decoder_state_h = Input(shape=(latent_dim*2,))\n",
    "    decoder_state_c = Input(shape=(latent_dim*2,))\n",
    "    decoder_states_inputs = [decoder_state_h, decoder_state_c]\n",
    "    \n",
    "    # decoder embedding\n",
    "    decoder_embedding = model.get_layer('decoder_embedding')(decoder_inputs)\n",
    "    # get rnn outputs and decoder states\n",
    "    rnn_outputs, *decoder_states = model.get_layer('decoder_lstm')(decoder_embedding, initial_state=decoder_states_inputs)\n",
    "    decoder_outputs = model.get_layer('decoder_dense')(rnn_outputs)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs]+decoder_states)\n",
    "    \n",
    "    return encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'bidi_encoder_model_best.h'\n",
    "inference_encoder_model, inference_decoder_model = build_bidi_encoder_inference_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: 59798\n",
      "Decoded sentence: 伍万玖仟柒佰玖拾捌元整终\n",
      "-\n",
      "Input sentence: 28307\n",
      "Decoded sentence: 贰万捌仟叁佰零柒元整终\n",
      "-\n",
      "Input sentence: 49323\n",
      "Decoded sentence: 肆万玖仟叁佰贰拾叁元整终\n",
      "-\n",
      "Input sentence: 24169\n",
      "Decoded sentence: 贰万肆仟壹佰陆拾玖元整终\n",
      "-\n",
      "Input sentence: 95323\n",
      "Decoded sentence: 玖万伍仟叁佰贰拾叁元整终\n",
      "-\n",
      "Input sentence: 50104\n",
      "Decoded sentence: 伍万零壹佰零肆元整终\n",
      "-\n",
      "Input sentence: 34650\n",
      "Decoded sentence: 叁万肆仟陆佰伍拾元整终\n",
      "-\n",
      "Input sentence: 60256\n",
      "Decoded sentence: 陆万零贰佰伍拾陆元整终\n",
      "-\n",
      "Input sentence: 42183\n",
      "Decoded sentence: 肆万贰仟壹佰捌拾叁元整终\n",
      "-\n",
      "Input sentence: 68802\n",
      "Decoded sentence: 陆万捌仟捌佰零贰元整终\n",
      "-\n",
      "Input sentence: 63819\n",
      "Decoded sentence: 陆万叁仟捌佰壹拾玖元整终\n",
      "-\n",
      "Input sentence: 32531\n",
      "Decoded sentence: 叁万贰仟伍佰叁拾壹元整终\n",
      "-\n",
      "Input sentence: 25678\n",
      "Decoded sentence: 贰万伍仟陆佰柒拾捌元整终\n",
      "-\n",
      "Input sentence: 42272\n",
      "Decoded sentence: 肆万贰仟贰佰柒拾贰元整终\n",
      "-\n",
      "Input sentence: 48908\n",
      "Decoded sentence: 肆万捌仟玖佰零捌元整终\n",
      "-\n",
      "Input sentence: 74546\n",
      "Decoded sentence: 柒万肆仟伍佰肆拾陆元整终\n",
      "-\n",
      "Input sentence: 11869\n",
      "Decoded sentence: 壹万壹仟捌佰陆拾玖元整终\n",
      "-\n",
      "Input sentence: 75803\n",
      "Decoded sentence: 柒万伍仟捌佰零叁元整终\n",
      "-\n",
      "Input sentence: 75727\n",
      "Decoded sentence: 柒万伍仟柒佰贰拾柒元整终\n",
      "-\n",
      "Input sentence: 67230\n",
      "Decoded sentence: 陆万柒仟贰佰叁拾元整终\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "for seq_index in range(len(test_input_texts)):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = test_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq, inference_encoder_model, inference_decoder_model)\n",
    "    print('-')\n",
    "    print('Input sentence:', test_input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFIwxxrhZUDDGGOP2/wFVA3TTyNliAwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fda5ab775f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 两种模型validation losss\n",
    "basic_model_val_loss = basic_model_hist.history['val_loss']\n",
    "bidi_model_val_loss = bidi_encoder_model_hist.history['val_loss']\n",
    "basic_model_train_loss = basic_model_hist.history['loss']\n",
    "bidi_model_train_loss = bidi_encoder_model_hist.history['loss']\n",
    "\n",
    "x_range = range(1, len(basic_model_val_loss)+1)\n",
    "plt.plot(x_range, basic_model_val_loss, 'r', label='Basic model validation loss')\n",
    "plt.plot(x_range, basic_model_train_loss, 'ro', label='Basic model Train loss')\n",
    "\n",
    "\n",
    "x_range = range(1, len(bidi_model_val_loss)+1)\n",
    "plt.plot(x_range, bidi_model_val_loss, 'b', label='Birirectianl model validation loss')\n",
    "plt.plot(x_range, bidi_model_train_loss, 'bo', label='Birirectianl model train loss')\n",
    "\n",
    "plt.plot()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "让我来总结下写代码时遇到的问题和坑\n",
    "1. 在实现双向编码器模型时，刚开始不知道如何将encoder的states作为decoder的初始状态，查了好一会才找到如何实现，并且似乎只有在keras 2.1.3以上版本有用，具体在 https://stackoverflow.com/questions/47923370/keras-bidirectional-lstm-seq2seq ，关键就是要将decoder的latent_dim*2\n",
    "2. 在预处理数据时，注意0的含义。在创建数据时，用的是np.zeros，如果0是代表着某个字符，那么训练将不正确，最好的办法是将0的含义设置为空\n",
    "3. 我还尝试着将decoder设计成双向的RNN，结果表明，训练阶段没有任何问题，能够得到很小的loss，但是在inference阶段，完全没有作用，因此我在想：是否在seq2seq模型中decoder只能是单向的\n",
    "4. 很明显，双向模型收敛速度快一些"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
